{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886ae7ed-28e9-4990-b4a6-e0fba51a2551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 1: Intuition \n",
    "'''\n",
    "graph TD\n",
    "  A[Original Text] --> B(AMR Parsing)\n",
    "  B --> C{AMR Graph}\n",
    "  C --> D[Graph Linearization]\n",
    "  D --> E[Graph Tokenization]\n",
    "  E --> F[BERT Embedding]\n",
    "  F --> G[Model Input]\n",
    "  '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2976ef-c9ef-4867-aa04-27dad7a85562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 2: AS2SP Model \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "import amrlib\n",
    "\n",
    "# SET CUDA \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# DATA LOADING\n",
    "def load_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "    articles = df['article'].tolist()\n",
    "    highlights = df['highlights'].tolist()\n",
    "    return articles, highlights\n",
    "\n",
    "train_articles, train_highlights = load_data(\"/home/masih/Downloads/Telegram Desktop/data/train.csv\") # REPLACE WITH YOUR PATH\n",
    "val_articles, val_highlights = load_data(\"/home/masih/Downloads/Telegram Desktop/data/validation.csv\")\n",
    "test_articles, test_highlights = load_data(\"/home/masih/Downloads/Telegram Desktop/data/test.csv\")\n",
    "\n",
    "# AMR PARSING & PREPROCESSING \n",
    "stog = amrlib.load_stog_model(device='cpu') \n",
    "\n",
    "def parse_amr(articles):\n",
    "    print(\"Parsing AMR graphs...\")\n",
    "    amr_graphs = stog.parse_sents(articles)\n",
    "    return [g if g else \"\" for g in amr_graphs]\n",
    "\n",
    "# Process all splits\n",
    "train_graphs = parse_amr(train_articles)\n",
    "val_graphs = parse_amr(val_articles)\n",
    "test_graphs = parse_amr(test_articles)\n",
    "\n",
    "# TOKENIZATION & VOCAB \n",
    "class Vocabulary:\n",
    "    def __init__(self):\n",
    "        self.word2idx = {\"<pad>\": 0, \"<unk>\": 1, \"<sos>\": 2, \"<eos>\": 3}\n",
    "        self.idx2word = {0: \"<pad>\", 1: \"<unk>\", 2: \"<sos>\", 3: \"<eos>\"}\n",
    "        \n",
    "    def build_vocab(self, texts, max_size=2000):\n",
    "        words = [word for text in texts for word in text.split()]\n",
    "        word_counts = Counter(words)\n",
    "        common_words = word_counts.most_common(max_size)\n",
    "        \n",
    "        for idx, (word, _) in enumerate(common_words, start=4):\n",
    "            self.word2idx[word] = idx\n",
    "            self.idx2word[idx] = word\n",
    "            \n",
    "VOCAB_SIZE = 2000\n",
    "vocab = Vocabulary()\n",
    "vocab.build_vocab(train_graphs + train_highlights, max_size=VOCAB_SIZE)\n",
    "\n",
    "# DATASET & DATALOADER \n",
    "class SummaryDataset(Dataset):\n",
    "    def __init__(self, graph_strings, highlights, vocab):\n",
    "        self.graphs = [self.text_to_ids(gs, vocab) for gs in graph_strings]\n",
    "        self.highlights = [self.text_to_ids(s, vocab, add_special=True) for s in highlights]\n",
    "        \n",
    "    def text_to_ids(self, text, vocab, add_special=False):\n",
    "        ids = [vocab.word2idx.get(word, 1) for word in text.split()]\n",
    "        if add_special:\n",
    "            ids = [vocab.word2idx[\"<sos>\"]] + ids + [vocab.word2idx[\"<eos>\"]]\n",
    "        return ids\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            torch.tensor(self.graphs[idx]),\n",
    "            torch.tensor(self.highlights[idx])\n",
    "        )\n",
    "\n",
    "def collate_fn(batch):\n",
    "    srcs, trgs = zip(*batch)\n",
    "    srcs = torch.nn.utils.rnn.pad_sequence(srcs, padding_value=0).transpose(0, 1)\n",
    "    trgs = torch.nn.utils.rnn.pad_sequence(trgs, padding_value=0).transpose(0, 1)\n",
    "    return srcs, trgs\n",
    "\n",
    "# CREATE DATASETS AND DATALOADERS\n",
    "train_dataset = SummaryDataset(train_graphs, train_highlights, vocab)\n",
    "val_dataset = SummaryDataset(val_graphs, val_highlights, vocab)\n",
    "test_dataset = SummaryDataset(test_graphs, test_highlights, vocab)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, collate_fn=collate_fn, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=2, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2, collate_fn=collate_fn)\n",
    "\n",
    "# MODEL ARCHITECTURE \n",
    "class AS2SP(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.enc_embed = nn.Embedding(vocab_size, 128)\n",
    "        self.encoder = nn.LSTM(128, 64, \n",
    "                             num_layers=1,\n",
    "                             bidirectional=True,\n",
    "                             batch_first=True)\n",
    "        self.hidden_proj = nn.Linear(64 * 2, 256)\n",
    "        self.cell_proj = nn.Linear(64 * 2, 256)\n",
    "        self.dec_embed = nn.Embedding(vocab_size, 128)\n",
    "        self.decoder = nn.LSTM(128, 256, num_layers=1, batch_first=True)\n",
    "        self.W_h = nn.Linear(64 * 2, 256)\n",
    "        self.W_s = nn.Linear(256, 256)\n",
    "        self.v = nn.Linear(256, 1)\n",
    "        self.p_gen = nn.Linear(128 + 256 + 128, 1)\n",
    "        self.fc = nn.Linear(256, vocab_size)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, src_graph, trg_text):\n",
    "        enc_embedded = self.dropout(self.enc_embed(src_graph))\n",
    "        enc_out, (h_n, c_n) = self.encoder(enc_embedded)\n",
    "        \n",
    "        h_n = torch.cat([h_n[0], h_n[1]], dim=-1)\n",
    "        c_n = torch.cat([c_n[0], c_n[1]], dim=-1)\n",
    "        \n",
    "        decoder_hidden = self.hidden_proj(h_n).unsqueeze(0)\n",
    "        decoder_cell = self.cell_proj(c_n).unsqueeze(0)\n",
    "        \n",
    "        dec_embedded = self.dropout(self.dec_embed(trg_text))\n",
    "        dec_out, _ = self.decoder(dec_embedded, (decoder_hidden, decoder_cell))\n",
    "        \n",
    "        enc_proj = self.W_h(enc_out).unsqueeze(2) \n",
    "        dec_proj = self.W_s(dec_out).unsqueeze(1)  \n",
    "        \n",
    "        attn_energy = torch.tanh(enc_proj + dec_proj)\n",
    "        attn_scores = self.v(attn_energy).squeeze(-1)\n",
    "        attn_weights = F.softmax(attn_scores, dim=1)\n",
    "        attn_weights = attn_weights.permute(0, 2, 1)\n",
    "        context = torch.bmm(attn_weights, enc_out)\n",
    "        \n",
    "        p_gen_input = torch.cat([context, dec_out, dec_embedded], dim=-1)\n",
    "        p_gen = torch.sigmoid(self.p_gen(p_gen_input))\n",
    "        \n",
    "        output = self.fc(dec_out)\n",
    "        return output, attn_weights, p_gen\n",
    "\n",
    "# TRAINING SETUP \n",
    "model = AS2SP(VOCAB_SIZE).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "# TRAINING LOOP \n",
    "for epoch in range(3):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_idx, (src, trg) in enumerate(train_loader):\n",
    "        src, trg = src.to(device), trg.to(device)\n",
    "        \n",
    "        outputs, _, _ = model(src[:, :-1], trg[:, :-1])\n",
    "        loss = criterion(outputs.reshape(-1, VOCAB_SIZE), \n",
    "                        trg[:, 1:].reshape(-1))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"Epoch: {epoch+1}, Batch: {batch_idx}, Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    print(f\"Epoch {epoch+1} Average Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "print(\"Training completed!\")\n",
    "\n",
    "# GENERATION FUNCTION \n",
    "def generate_summary(model, graph_string, vocab, max_len=20):\n",
    "    model.eval()\n",
    "    tokenized = [vocab.word2idx.get(word, 1) for word in graph_string.split()]\n",
    "    src = torch.tensor([tokenized]).to(device)\n",
    "    \n",
    "    decoder_input = torch.tensor([[vocab.word2idx[\"<sos>\"]]]).to(device)\n",
    "    summary = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        enc_embedded = model.enc_embed(src)\n",
    "        enc_out, (h_n, c_n) = model.encoder(enc_embedded)\n",
    "        \n",
    "        h_n = torch.cat([h_n[0], h_n[1]], dim=-1)\n",
    "        c_n = torch.cat([c_n[0], c_n[1]], dim=-1)\n",
    "        decoder_hidden = model.hidden_proj(h_n).unsqueeze(0)\n",
    "        decoder_cell = model.cell_proj(c_n).unsqueeze(0)\n",
    "        \n",
    "        for _ in range(max_len):\n",
    "            dec_embedded = model.dec_embed(decoder_input)\n",
    "            dec_out, (decoder_hidden, decoder_cell) = model.decoder(\n",
    "                dec_embedded, (decoder_hidden, decoder_cell)\n",
    "            )\n",
    "            \n",
    "            output = model.fc(dec_out)\n",
    "            next_token = output.argmax(-1)[:, -1].item()\n",
    "            \n",
    "            if next_token == vocab.word2idx[\"<eos>\"]:\n",
    "                break\n",
    "            \n",
    "            summary.append(vocab.idx2word.get(next_token, \"<unk>\"))\n",
    "            decoder_input = torch.tensor([[next_token]]).to(device)\n",
    "            \n",
    "    return \" \".join(summary)\n",
    "\n",
    "# GENERATE SUMMARIES FOR TEST SET\n",
    "print(\"\\nGenerated Summaries for Test Set:\")\n",
    "for i in range(len(test_dataset)):\n",
    "    input_graph = test_graphs[i]\n",
    "    generated = generate_summary(model, input_graph, vocab)\n",
    "    print(f\"Original Article: {test_articles[i]}\")\n",
    "    print(f\"Generated Summary: {generated}\")\n",
    "    print(f\"Reference Summary: {test_highlights[i]}\\n{'-'*50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd40ba0d-f7dd-42cd-b331-152bacc02dab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
