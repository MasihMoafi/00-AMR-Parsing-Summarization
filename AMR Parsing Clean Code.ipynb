{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e0dbb6-50f7-404c-b6f6-55fd83258267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== CELL 0: Intuition ==========\n",
    "\n",
    "'''\n",
    "graph TD\n",
    "  A[Original Text] --> B(AMR Parsing)\n",
    "  B --> C{AMR Graph}\n",
    "  C --> D[Graph Linearization]\n",
    "  D --> E[Graph Tokenization]\n",
    "  E --> F[BERT Embedding]\n",
    "  F --> G[Model Input]\n",
    "  '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff76ef78-aca8-4c82-b405-b2b90453f294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== CELL 1: AMR Parsing & Preprocessing ==========\n",
    "import amrlib\n",
    "import pandas as pd\n",
    "\n",
    "# Load AMR parser\n",
    "stog = amrlib.load_stog_model(device='cpu')\n",
    "\n",
    "# Load CSV data\n",
    "df = pd.read_csv('/data/path.csv')  # Replace with your data path\n",
    "original_texts = df['text'].tolist()\n",
    "summaries = df['summary'].tolist()\n",
    "\n",
    "# Convert text to AMR graphs\n",
    "print(\"Parsing AMR graphs...\")\n",
    "amr_graphs = stog.parse_sents(original_texts)\n",
    "\n",
    "# Parse graphs to linearized format\n",
    "print(\"Linearizing graphs...\")\n",
    "graph_strings = [g.to_penman(remove_wiki=True) for g in amr_graphs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8416d2-672f-4cd0-af43-654a9bd40f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== CELL 2: AS2SP Model (Exact Paper Specs) ==========\n",
    "class AS2SP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Encoder (BiLSTM)\n",
    "        self.enc_embed = nn.Embedding(VOCAB_SIZE, 768) # Differs based on data\n",
    "        self.encoder = nn.LSTM(768, 256//2, \n",
    "                              num_layers=2,\n",
    "                              bidirectional=True,\n",
    "                              dropout=0.3)\n",
    "        \n",
    "        # Decoder (LSTM)\n",
    "        self.dec_embed = nn.Embedding(VOCAB_SIZE, 768)\n",
    "        self.decoder = nn.LSTM(768, 512, dropout=0.3)\n",
    "        \n",
    "        # Attention (with coverage)\n",
    "        self.W_h = nn.Linear(256, 512)\n",
    "        self.W_s = nn.Linear(512, 512)\n",
    "        self.W_cov = nn.Linear(1, 512)\n",
    "        self.v = nn.Linear(512, 1)\n",
    "        \n",
    "        # Pointer-Generator\n",
    "        self.p_gen = nn.Linear(256 + 512 + 768, 1)\n",
    "        self.fc = nn.Linear(512, VOCAB_SIZE) \n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, src_graph, trg_text, cov_vec=None):\n",
    "        # Encoder processing AMR graph\n",
    "        enc_embedded = self.dropout(self.enc_embed(src_graph))\n",
    "        enc_out, (h_n, c_n) = self.encoder(enc_embedded)\n",
    "        \n",
    "        # Merge bidirectional states\n",
    "        h_n = torch.cat((h_n[-2], h_n[-1]), dim=1).unsqueeze(0)\n",
    "        c_n = torch.cat((c_n[-2], c_n[-1]), dim=1).unsqueeze(0)\n",
    "        \n",
    "        # Decoder processing target text\n",
    "        dec_embedded = self.dropout(self.dec_embed(trg_text))\n",
    "        dec_out, (h_d, _) = self.decoder(dec_embedded, (h_n, c_n))\n",
    "        \n",
    "        # Attention with coverage\n",
    "        attn_energy = torch.tanh(\n",
    "            self.W_h(enc_out) + \n",
    "            self.W_s(h_d[-1].unsqueeze(1)) + \n",
    "            (self.W_cov(cov_vec.unsqueeze(-1)) if cov_vec is not None else 0)\n",
    "        )\n",
    "        attn_weights = F.softmax(self.v(attn_energy).squeeze(2), dim=1)\n",
    "        \n",
    "        # Context vector\n",
    "        context = torch.bmm(attn_weights.unsqueeze(1), enc_out).squeeze(1)\n",
    "        \n",
    "        # Pointer-Generator\n",
    "        p_gen = torch.sigmoid(self.p_gen(\n",
    "            torch.cat([context, h_d[-1], dec_embedded.squeeze(1)], dim=1)\n",
    "        ))\n",
    "        \n",
    "        # Final output\n",
    "        output = self.fc(dec_out.squeeze(1))\n",
    "        return output, attn_weights, p_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0bab4c-7ae6-464a-9666-08f56267d1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== CELL 3: Verification Checklist ==========\n",
    "\n",
    "'''\n",
    "# AMR Processing:\n",
    "\n",
    "Text â†’ AMR graphs using amrlib\n",
    "\n",
    "Graph linearization to penman format\n",
    "\n",
    "Graph tokenization as model input\n",
    "\n",
    "# Model Architecture:\n",
    "\n",
    "2-layer bidirectional LSTM encoder\n",
    "\n",
    "1-layer LSTM decoder\n",
    "\n",
    "Attention with coverage mechanism\n",
    "\n",
    "Pointer-generator network\n",
    "\n",
    "Dropout (0.3) and gradient clipping (2.0)\n",
    "\n",
    "# Training Parameters:\n",
    "\n",
    "Batch size 64/32\n",
    "\n",
    "Learning rate 0.001\n",
    "\n",
    "Adam optimizer\n",
    "\n",
    "15 epochs\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
